{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkred\">Motor Vehicle Collisions in New York City</span>\n",
    "### <span style=\"color:darkred\">Final Project - Explainer Notebook</span>\n",
    "---\n",
    "\n",
    "This report is written in the course 02806 Social Data Analysis, spring 2017, based on the assignment description for the final exam project found on [GitHub](https://github.com/suneman/socialdataanalysis2017/wiki/Final-Project). \n",
    "\n",
    "![Why New York City looks like it does](traffic.png)\n",
    "\n",
    "Source: [Business Insider, fetched April 2017](http://www.businessinsider.com/why-new-york-city-looks-like-it-does-2015-9?r=US&IR=T&IR=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkred\">Motivation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:darkred\">What is your dataset?</span>\n",
    "\n",
    "The dataset chosen for this project is the  **\"NYC Motor Vehicle Traffic Collisions\"** dataset from the Public Safety section from the website of [New York City OpenData](http://opendata.cityofnewyork.us/). This contains traffic collision data for boroughs: Manhattan, Staten Island, Bronx, Queens and Brooklyn.\n",
    "\n",
    "Looking into where accidents happen and cross-referencing this information with the traffic density to find the areas most commonly exposed to accidents, could be used in order to *improve the safety of pedestrians* and to *take proper precautions* for the vehicles in the area whether this concerns either more mirror, traffic regulations etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:darkred\">Why did you choose this/these particular dataset(s)?</span>\n",
    "\n",
    "We knew that we wanted to work with some sort of OpenData from a large city in the world. Going through different OpenData sources such as [London OpenData](https://data.london.gov.uk/), [SF OpenData](https://data.sfgov.org/), [European OpenData](https://open-data.europa.eu) that what seemed as a lot of different opportunities in chosing data, was in fact not. A lot of the publicly available data was lacking either in size (only a few years) or extremely badly formatted, only with a few features, a lot of missing values etc. What would be nice was if there were several years (5-10) and lots of different features to chose from. This way it would be possible to take some active choices on what to keep or discard and chose what was important for predictions, basic statistics and so on.\n",
    "\n",
    "Looking into [NYC OpenData](http://opendata.cityofnewyork.us/) and the Public Safety Category, the \"Traffic Collisions\" dataset was discovered. Here we get information on where in New York different traffic collisions happens, a timestamp for the accident, the involved parties (pedestrian, motorist biker..), whether any involved parties were killed, which type of vehicle, whether the driver was distrated/unattentive -- the contributing factors, geolocations -- a great level of detail to work on and make predictions on. More on the features of the dataset will be discussed below, first we discuss the end user's experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">What was your goal for the end user's experience?</span>\n",
    "\n",
    "<span style=\"color:red\">Should we write this more as text -- and probably focus more on the death part?</span>\n",
    "\n",
    "* Explore the data that is freely available to everyone\n",
    "* Getting to know something new about the traffic in New York\n",
    "* Learning from the patterns that can be found in the data\n",
    "* Prevent accident in the future by localizing exposed areas that need saftey improvements.\n",
    "\n",
    "From this notebook, we will try to extract some of the most informative summary staatistics and the results of our machine learning methods to try and give a better insight into the traffic in New York and when accidents happen. \n",
    "\n",
    "### <span style=\"color:darkred\">What data to look into</span>\n",
    "#### <span style=\"color:darkred\">Deaths</span>\n",
    "* Where do they happen\n",
    "* what is the underlying cause\n",
    "* can this be prevented? \n",
    "* What is being done in NYC now? - Read more about [*Vision Zero*](http://www1.nyc.gov/nyc-resources/service/3860/nyc-vision-zero-action-plan)\n",
    "* Wordcloud of different addresses?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Libraries</span>\n",
    "**Importing needed packages for entire solution**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import urllib2\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import io\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\",5) # show a maximum of 10 rows in dataframe\n",
    "import geoplotlib as gpl\n",
    "from geoplotlib.utils import BoundingBox\n",
    "import calendar\n",
    "import pylab as pl\n",
    "import geopy\n",
    "import json\n",
    "from collections import Counter \n",
    "from operator import itemgetter\n",
    "from scipy import stats, linalg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, datasets, svm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Geopy - location\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim()\n",
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "# Plotting with plotly\n",
    "import plotly \n",
    "from IPython.display import Image\n",
    "# Henriettes plotly API key og brugernavn -- saves plot in cloud\n",
    "plotly.tools.set_credentials_file(username='frksteenhoff2', api_key='duu8hsfRmuI5rF2EU8o5')\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "\n",
    "# Functions tailored for this project to minimize code in notebook \n",
    "import externalFunctions as ex\n",
    "\n",
    "# Plotting color variables\n",
    "bgBorder  = 'rgba(255, 255, 255, 0)'\n",
    "ticksAxes = 'rgb(107, 107, 107)'\n",
    "years_of_interest = [2013, 2014, 2015, 2016]\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "try:\n",
    "    to_unicode = unicode\n",
    "except NameError:\n",
    "    to_unicode = str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:darkred\">Looking at the raw data</span>\n",
    "In order to discuss the data, some of the rows from the dataset are visualized below such that it is easier to understand some of the decisions made by the group when it comes to preprocessing and cleaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>ON STREET NAME</th>\n",
       "      <th>NUMBER OF PERSONS KILLED</th>\n",
       "      <th>NUMBER OF PEDESTRIANS KILLED</th>\n",
       "      <th>NUMBER OF CYCLIST KILLED</th>\n",
       "      <th>NUMBER OF MOTORIST KILLED</th>\n",
       "      <th>CONTRIBUTING FACTOR VEHICLE 1</th>\n",
       "      <th>VEHICLE TYPE CODE 1</th>\n",
       "      <th>VEHICLE TYPE CODE 2</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>WEEKDAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/31/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.645615</td>\n",
       "      <td>-73.90990</td>\n",
       "      <td>(40.645615, -73.9099)</td>\n",
       "      <td>FOSTER AVENUE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Driver Inattention/Distraction</td>\n",
       "      <td>PASSENGER VEHICLE</td>\n",
       "      <td>PASSENGER VEHICLE</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/31/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.762737</td>\n",
       "      <td>-73.83951</td>\n",
       "      <td>(40.762737, -73.83951)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Driver Inattention/Distraction</td>\n",
       "      <td>SPORT UTILITY / STATION WAGON</td>\n",
       "      <td>PASSENGER VEHICLE</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/31/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.658478</td>\n",
       "      <td>-73.92818</td>\n",
       "      <td>(40.658478, -73.92818)</td>\n",
       "      <td>EAST 53 STREET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Failure to Yield Right-of-Way</td>\n",
       "      <td>SPORT UTILITY / STATION WAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/31/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.580360</td>\n",
       "      <td>-73.96761</td>\n",
       "      <td>(40.58036, -73.96761)</td>\n",
       "      <td>NEPTUNE AVENUE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/31/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.845180</td>\n",
       "      <td>-73.91417</td>\n",
       "      <td>(40.84518, -73.91417)</td>\n",
       "      <td>JEROME AVENUE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Following Too Closely</td>\n",
       "      <td>PASSENGER VEHICLE</td>\n",
       "      <td>SPORT UTILITY / STATION WAGON</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  TIME   BOROUGH   LATITUDE  LONGITUDE                LOCATION  \\\n",
       "0  03/31/2017  0:00       NaN  40.645615  -73.90990   (40.645615, -73.9099)   \n",
       "1  03/31/2017  0:00       NaN  40.762737  -73.83951  (40.762737, -73.83951)   \n",
       "2  03/31/2017  0:00  BROOKLYN  40.658478  -73.92818  (40.658478, -73.92818)   \n",
       "3  03/31/2017  0:00  BROOKLYN  40.580360  -73.96761   (40.58036, -73.96761)   \n",
       "4  03/31/2017  0:00       NaN  40.845180  -73.91417   (40.84518, -73.91417)   \n",
       "\n",
       "                     ON STREET NAME  NUMBER OF PERSONS KILLED  \\\n",
       "0  FOSTER AVENUE                                            0   \n",
       "1                               NaN                         0   \n",
       "2  EAST 53 STREET                                           0   \n",
       "3  NEPTUNE AVENUE                                           0   \n",
       "4  JEROME AVENUE                                            0   \n",
       "\n",
       "   NUMBER OF PEDESTRIANS KILLED  NUMBER OF CYCLIST KILLED  \\\n",
       "0                             0                         0   \n",
       "1                             0                         0   \n",
       "2                             0                         0   \n",
       "3                             0                         0   \n",
       "4                             0                         0   \n",
       "\n",
       "   NUMBER OF MOTORIST KILLED   CONTRIBUTING FACTOR VEHICLE 1  \\\n",
       "0                          0  Driver Inattention/Distraction   \n",
       "1                          0  Driver Inattention/Distraction   \n",
       "2                          0   Failure to Yield Right-of-Way   \n",
       "3                          0                             NaN   \n",
       "4                          0           Following Too Closely   \n",
       "\n",
       "             VEHICLE TYPE CODE 1            VEHICLE TYPE CODE 2  YEAR  MONTH  \\\n",
       "0              PASSENGER VEHICLE              PASSENGER VEHICLE  2017      3   \n",
       "1  SPORT UTILITY / STATION WAGON              PASSENGER VEHICLE  2017      3   \n",
       "2  SPORT UTILITY / STATION WAGON                            NaN  2017      3   \n",
       "3                            NaN                            NaN  2017      3   \n",
       "4              PASSENGER VEHICLE  SPORT UTILITY / STATION WAGON  2017      3   \n",
       "\n",
       "   HOUR  WEEKDAY  \n",
       "0     0        4  \n",
       "1     0        4  \n",
       "2     0        4  \n",
       "3     0        4  \n",
       "4     0        4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data using pandas\n",
    "traffic_data = pd.read_csv('Traffic_data.csv', low_memory=False, usecols=['DATE', 'TIME', 'YEAR', 'MONTH', 'HOUR', 'WEEKDAY', 'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2', 'ON STREET NAME', 'LOCATION', 'LONGITUDE', 'LATITUDE', 'BOROUGH', 'CONTRIBUTING FACTOR VEHICLE 1', 'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST KILLED']) # Data fetched April\n",
    "\n",
    "# Giving an example of how the data is structured (features etc.)\n",
    "traffic_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- BASIC INFORMATIOM FROM DATASET ON NYC COLLISIONS --------------\n",
      "\n",
      "Year range:     [2012, 2013, 2014, 2015, 2016, 2017]\n",
      "\n",
      "Date range:     01/01/2013 - 12/31/2016\n",
      "\n",
      "Dataset size:   1007130 incidents\n",
      "\n",
      "List of areas:  [nan 'BROOKLYN' 'BRONX' 'MANHATTAN' 'QUEENS' 'STATEN ISLAND']\n",
      "\n",
      "Features:       ['DATE', 'TIME', 'BOROUGH', 'LATITUDE', 'LONGITUDE', 'LOCATION', 'ON STREET NAME', 'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST KILLED', 'CONTRIBUTING FACTOR VEHICLE 1', 'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2', 'YEAR', 'MONTH', 'HOUR', 'WEEKDAY'] \n",
      "\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print \"-------------- BASIC INFORMATIOM FROM DATASET ON NYC COLLISIONS --------------\\n\" \n",
    "print \"Year range:    \", sorted(traffic_data['YEAR'].unique())\n",
    "print \"\\nDate range:    \" , min(traffic_data[\"DATE\"]), \"-\", max(traffic_data[\"DATE\"]) \n",
    "print \"\\nDataset size:  \", len(traffic_data), \"incidents\"\n",
    "print \"\\nList of areas: \", traffic_data['BOROUGH'].unique()\n",
    "print \"\\nFeatures:      \", list(traffic_data.columns), \"\\n\"\n",
    "print \"------------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkred\">The initial dataset</span>\n",
    "The original dataset has 29 columns. For ease of access to data, and to minimize computing time when working on the data, it was decided to extend the dataset with the features ``TIME, HOUR, WEEKDAY, MONTH, YEAR`` from the given timestamps of each incident. The features were calculated once and saved to the original dataset for further use. The calculations take a substantial amount of time and the group found that this was an easier solution than having to run this upon every new session.\n",
    "\n",
    "In all we have $29$ features and $1.007.310$ different incidents from July 2012 until March 24th 2017 -- the data is soo fresh! In some of our work with the data, we will be excluding year 2012 and 2017, since we only have the first and the two first Quarters 2017 and 2012, respectively. When excluded this will be stated explicitly. \n",
    "\n",
    "### <span style=\"color:darkred\">Choices in data cleaning and preprocessing</span> \n",
    "#### <span style=\"color:darkred\">Finding relevant features</span>\n",
    "We have removed the features ..... since they will be oof no use for our work. <span style=\"color:red\">Need to write some more here, Jonas?</span>\n",
    "* Why include/exclude a feature\n",
    "* What is relevant/irrelevant\n",
    "* Plotting different boroughs at different times, years per different vehicles etc.\n",
    "\n",
    "#### <span style=\"color:darkred\">Handling missing values</span>\n",
    "\n",
    "##### Are missing values a problem in the dataset?\n",
    "To answer the questions regarding missing values we will show some exampels from the data. We start by giving an example of a feature, ``LOCATION``, with missing values. Here we assume that a missing ``LONGITUDE`` also means a missing ``LATITUDE`` -- both are assumend calculated on the basis of the feature ``LOCATION`` and since this is the root cause of the problem, this is the feature we choose. For this example we have extracted the missing values for each month in 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accidents in all in NYC, 2016:   227,658\n",
      "Accidents with geolocations:     145,529\n",
      "% of accidents missing location: 36.08 %\n",
      "\n",
      "Month:    All values: Complete obs:   Missing location (%):\n",
      "JANUARY   18,099      15,395          14.94%\n",
      "FEBRUARY  15,983      13,557          15.18%\n",
      "MARCH     18,520      15,300          17.39%\n",
      "APRIL     18,331      15,062          17.83%\n",
      "MAY       20,052      15,311          23.64%\n",
      "JUNE      19,435      13,974          28.1%\n",
      "JULY      19,867      12,527          36.95%\n",
      "AUGUST    19,678      2,496           87.32%\n",
      "SEPTEMBER 19,491      3,039           84.41%\n",
      "OCTOBER   19,667      12,367          37.12%\n",
      "NOVEMBER  19,317      13,226          31.53%\n",
      "DECEMBER  19,218      13,275          30.92%\n"
     ]
    }
   ],
   "source": [
    "allData = pd.DataFrame()\n",
    "misData = pd.DataFrame()\n",
    "\n",
    "year = [2016]\n",
    "feature = \"LOCATION\"\n",
    "\n",
    "# Extract data to look at (year 2016)\n",
    "allData = traffic_data.loc[traffic_data['YEAR'].isin(year)]\n",
    "# Find all missing values in column (\"LONGITUDE\")\n",
    "\n",
    "allData[feature] = allData[feature].replace(np.NaN, 'UNKNOWN')\n",
    "misData = allData.loc[allData[feature] != 'UNKNOWN']\n",
    "\n",
    "# Print results (more or less) neatly\n",
    "print \"Accidents in all in NYC, 2016:  \", '{0:,}'.format(len(allData))\n",
    "print \"Accidents with geolocations:    \", '{0:,}'.format(len(misData))\n",
    "print \"% of accidents missing location:\", round(100.0-float(len(misData))/float(len(allData))*100, 2), \"%\\n\" \n",
    "print \"Month:    All values: Complete obs:   Missing location (%):\"\n",
    "# For each month in given year\n",
    "for numb in sorted(allData['MONTH'].unique()):\n",
    "    all_vals   = len(allData.loc[allData['MONTH'].isin([numb])])\n",
    "    nonan_vals = len(misData.loc[misData['MONTH'].isin([numb])])\n",
    "    print calendar.month_name[numb].upper().ljust(9), str('{0:,}'.format(all_vals)).ljust(10) + \"  \" + str('{0:,}'.format(nonan_vals)).ljust(12), \"   \" + str(round(100-float(nonan_vals) / float(all_vals) * 100, 2)) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we can see that for the whole dataset, mor than $\\frac{1}{3}$ of the location values are missing! Trust us when we say that as it often is with real data, missing values are a general trend. If not, feel free to change the ``YEAR/FEATURE`` used for extracting the data and look at it yourselves.\n",
    "\n",
    "The above analysis of the missing values for location (``lon/lat``) show that the number of observations with missing values is really high. Here we are only looking into 2016, but from this alone we can see that for each month more than $14\\%$ of the values are missing. The $15\\%$ itself is not alarming, but $50\\%$ of the months, more than $\\frac{1}{4}$ of the values are missing! Especially the summer months are lacking information -- here $15\\%$ is actually what is registered correctly.   \n",
    "\n",
    "In the following sections we will comment on the missing values problem for the features relevant to our further work one by one. \n",
    "\n",
    "##### How will missing values affect our results?\n",
    "From the preliminary analysis a set of features was flagged as in need of some work in order to present the proper picture of the NYC traffic. Since we want to look into where accidents happen, why they happen it is important to have as much data as possible. Overall, what we would like is to impute the missing values with correct values where it is possible. This means that if we have the location, but we are missing the street name, we would like to compute the one based on the other. Some of our most important features with many missing values are: ``LOCATION``, ``BOROUGH``, ``ON STREET NAME`` and ``CONRIBUTING FACTORS VEHICLE 1``. These features and the considered methods for imputing the values and the final result will now be discussed. The number of missing values are calculated based on 2016 data since this will be one of te years most commonly used.\n",
    "\n",
    "##### Contributing factors\n",
    "Feature(s): ``CONTRIBUTING FACTOR VEHICLE 1``\n",
    "* Percentage of values missing: $~1\\%$\n",
    "\n",
    "Contributing factors is hard to infer from nothing. One way to work around the problem would be to impute the values with the $mode$ -- the most frequently occuring value. This would mean that the $1\\%$ of the observations missing a value would be imputed with ``DRIVER INATTENTION``. However this would falsly inflate the number of accidents with this contributing factor and since we are going to apply some machine learning tools on this feature we would want the data to eb \"as pure\" as possible. We ended up chosing to exclude the observations where contributing factor was missing, even though this might not be optimal solution.\n",
    "\n",
    "##### Location information\n",
    "Features: ``ON STREET NAME``, ``LONGITUDE/LATITUDE/LOCATION``, ``BOROUGH``\n",
    "* Percentage of values missing ``ON STREET NAME``: $~19\\%$\n",
    "* Percentage of values missing ``LON/LAT/LOC``:    $~36\\%$\n",
    "* Percentage of values missing: ``BOROUGH``:       $~32\\%$\n",
    "\n",
    "*Location (geo-location), address (street name), borough*\n",
    "\n",
    "All of these columns concern location just on different levels. Coordinates which is the most precise, street name that describe a larger, still well-defined area, and boroughs that look at a larger geographically defined area. As can be seen from the percentage given above, in all of the columns, there are several missing values.  \n",
    "\n",
    "The reason why we are describing these features together is because they all can be imputed using the same python module, namely ``geopy``. The module matches, ``lon/lat``-pairs to find a street name or street names and city to ``lon/lat``-pairs, which is exactly what we need! Below we have tried to map the number of observations missing the different featured mentioned and give an example of how ``geopy`` works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266674, 202343, 168104)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replce missing borough values with \"unspecified\"\n",
    "traffic_data['BOROUGH']        = traffic_data['BOROUGH'].replace(np.NaN, 'Unspecified')\n",
    "traffic_data['LOCATION']       = traffic_data['LOCATION'].replace(np.NaN, 'Unspecified')\n",
    "traffic_data['ON STREET NAME'] = traffic_data['ON STREET NAME'].replace(np.NaN, 'Unspecified')\n",
    "\n",
    "# Extract the unspecified values\n",
    "missing_bor = traffic_data.loc[traffic_data['BOROUGH']        == 'Unspecified']\n",
    "missing_loc = traffic_data.loc[traffic_data['LOCATION']       == 'Unspecified']\n",
    "missing_st  = traffic_data.loc[traffic_data['ON STREET NAME'] == 'Unspecified']\n",
    "\n",
    "# Number of missing values for each feature in dataset \n",
    "len(missing_bor), len(missing_loc), len(missing_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49852"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all observations missing borough, location AND street name\n",
    "missing_bl = missing_bor.loc[missing_bor['LOCATION'] == 'Unspecified']\n",
    "all_3      = missing_bl.loc[missing_bl['ON STREET NAME'] == 'Unspecified']\n",
    "len(all_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost $50,000$ rows are missing both ``location``, ``on street name`` and ``borough``. This is not that much considering that we are working $20$ times as much data.\n",
    "\n",
    "##### ``geopy`` and how it works\n",
    "Let's give an example, we have the coordinates, and want street name/borough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Van Wyck Expressway, Queens, Queens County, NYC, New York, 11368, United States of America'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = geolocator.reverse(\"40.762737, -73.83951\")\n",
    "location.address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, by giving the geolocation for a feature with a missing street address, we can extract the street name from the ``location`` object with the call to ``.address``. If we want to go the other way (finding geolocations from street name) we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location((40.68718, -73.8080149, 0.0))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = geolocator.geocode(\"Van Wyck Expressway, New York City\")\n",
    "location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, from geolocation we get a string where we can extract an address and the borough. By giving the street name and city, which will always be New York, we get the geolocations, which is exactly what we want.\n",
    "\n",
    "However. We have run in to one major problem. The number of times you can call the ``geopy`` API per day is not enough for our purposes, as we have to make an excessive amount of calls, even if we extract both address and borough in the same call. Therefore, we have not been able to impute all our values correctly. Therefore, for the most of our data analysis, missing values have been excluded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkred\">Summary statistics and basic plotting</span>\n",
    "### <span style=\"color:darkred\">Write a short section that discusses the dataset stats (here you can recycle the work you did for Project Assignment A)</span>\n",
    "\n",
    "To get an idea of the traffic situation in New York, what types of incidents, their outcome, what is the most common places for accidents to happen etc. we have done some different plotting of all collisions historically, per year, per borough and for specific vehicle types, times of day etc. Thus we hope to give you a better idea of the traffic scene in NYC.\n",
    "\n",
    "The plots will start by describing basic summary statistics but will increase in complexity throughout the notebook. The plots will all be rendered using ``plotly`` and it's API in order to minimize the length of the notebook by exhibiting more information as mouse-over visuals directly in the plot itself.\n",
    "\n",
    "The description associated with each plot will be positioned underneath the plots such that the reader can get a chance to make his/her own thoughts about the data before we bring our comments.\n",
    "\n",
    "### <span style=\"color:darkred\"> Inflicted boroughs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~frksteenhoff2/90.embed\" height=\"700px\" width=\"900px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count incidents in each borough\n",
    "borough_cnt = ex.countSamples(traffic_data['BOROUGH'].replace(np.NaN, 'Unspecified'))\n",
    "\n",
    "# Plot them\n",
    "ex.createBarPlot(borough_cnt, 'Collisions per borough in all', 'Borough', 'Number of collisions', 'collisions_all', bgBorder, ticksAxes, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot it is easy to see that we are working with a lot of missing data (seen in bar \"Unspecified\"). If we however, overlook this for a while it looks as if Brooklyn is the borough where most accidents happen. Staten Island is by far the least inflicted borough, knowing it's geographical location and position relative to Manhattan/Brooklyn this makes good sense. Queens and Manhattan seem to have approximately the same number of accidents. \n",
    "\n",
    "We will look into whether this picture portrays the reality correct later with some geoplotting with ``geoplotlib``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Plotting the accidents</span>\n",
    "Since we have a lot of missing information in the dataset, we chose to check whether the number of accidents would look the same plotted on a density map as it does when making the bar chart. \n",
    "\n",
    "Becuase of the high number of accidents each year, we have chosen only to plot a single month (May 2016) to give an idea of how "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current month: 11\n",
      "Samples: 15888\n",
      "('smallest non-zero count', 1.7910636084771928e-08)\n",
      "('max count:', 4.4128054383942352)\n",
      "Current month: 10\n",
      "Samples: 16861\n",
      "('smallest non-zero count', 1.7910636084771928e-08)\n",
      "('max count:', 3.0090484602706904)\n",
      "Current month: 12\n",
      "Samples: 17119\n",
      "('smallest non-zero count', 1.7910636084771928e-08)\n",
      "('max count:', 2.8426840225271008)\n",
      "Current month: 9\n",
      "Samples: 16532\n",
      "('smallest non-zero count', 1.7910636084771928e-08)\n",
      "('max count:', 3.2003116722806988)\n",
      "Current month: 8\n",
      "Samples: 17139\n",
      "('smallest non-zero count', 1.7910636084771928e-08)\n",
      "('max count:', 3.9328953814849217)\n",
      "Current month: 7\n",
      "Samples: 16988\n",
      "('smallest non-zero count', 1.7910636084771928e-08)\n",
      "('max count:', 3.1174848381808618)\n"
     ]
    }
   ],
   "source": [
    "yearData = traffic_data.loc[traffic_data['YEAR'].isin([2012])]\n",
    "#oneMonth = yearData.loc[yearData['MONTH'].isin([5])] \n",
    "ex.plotGeoData(yearData, 'MONTH', \"Current month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Primary vehicle in collision - per vehicle type</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~frksteenhoff2/86.embed\" height=\"700px\" width=\"900px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace NaN with 'unknown'\n",
    "vehicle_types = traffic_data['VEHICLE TYPE CODE 1'].replace(np.NaN, 'OTHER')\n",
    "\n",
    "# Count key/value pairs\n",
    "collision_count = ex.countSamples(vehicle_types)\n",
    "\n",
    "# createBarPlot(valueDict, plotTitle, xtitle, ytitle, saveName, bgBorder, ticksAxes, marginValue):\n",
    "vehicles = ex.createBarPlot(collision_count, 'Primary vehicle in collison, NY 2012-2017', 'Vehicle type', 'Number of incidents', 'vechicle2', bgBorder, ticksAxes, 200)\n",
    "vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passenger vehicles and sport/utility wagons are by far the two vehicle types that are most commonly involved in accidents. Out of the total of $1.007.130$ accidents, passenger vehicles are involved in more than $50\\%$ of the accidents while the sport/utility wagon only account less than half of that. This visualization is also added on the webpage and will be described in further detail there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save as json object for website\n",
    "with open('primary_vehicle.json', 'w') as fp:\n",
    "    json.dump(collision_count.most_common(), fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Vehicle collisions - per contributing factor</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~frksteenhoff2/88.embed\" height=\"700px\" width=\"900px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace NaN with 'Unspecified'\n",
    "factor_types = traffic_data['CONTRIBUTING FACTOR VEHICLE 1'].replace(np.NaN, 'Unspecified')\n",
    "\n",
    "# Count number of occurences of the different categories\n",
    "factor_count = ex.countSamples(factor_types)\n",
    "\n",
    "# Remove unspecified in order to get a better picture of remaining entries\n",
    "del factor_count['Unspecified']\n",
    "\n",
    "# Save as json object for website\n",
    "with open('factor_data.json', 'w') as fp:\n",
    "    json.dump(factor_count.most_common(25), fp)\n",
    "\n",
    "# createBarPlot(valueDict, plotTitle, xtitle, ytitle, saveName, bgBorder, ticksAxes, marginValue):\n",
    "factors = ex.createBarPlot(factor_count, 'Contributing factors for collisions, NY 2012-2017', 'Reason/factor', 'Number of incidents', 'factors', bgBorder, ticksAxes, 250)\n",
    "factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the primary vehicle in collison and the contributiog factors are included as visualization on the final webpage. These two summary statistics show some of the basic facts about the different traffic accidents in New York and gives us a chance to show how to work with switching between different datasets in the same visualization, how to create the initial bar chart and update it with completely new values for both axes. We think this is a good way to show that we have understood the basic functionalities within the d3 visualization techniques when creating bar chart while it also gives the reader some intial information about the traffic in NYC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\"> Plotting the collisions per year</span>\n",
    "Consider removing data from 2017, since the data is not complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]    [ (1,2) x2,y2 ]  \n",
      "[ (2,1) x3,y3 ]    [ (2,2) x4,y4 ]  \n",
      "[ (3,1) x5,y5 ]    [ (3,2) x6,y6 ]  \n",
      "[ (4,1) x7,y7 ]    [ (4,2) x8,y8 ]  \n",
      "[ (5,1) x9,y9 ]    [ (5,2) x10,y10 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~frksteenhoff2/56.embed\" height=\"1200px\" width=\"1000px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 2 X 5 grid for the 10 collision subplots\n",
    "# Initialize variables\n",
    "vehicle_types = ['PASSENGER VEHICLE', 'SPORT UTILITY / STATION WAGON',\n",
    "                'VAN','BUS','SMALL COM VEH(4 TIRES)', 'LIVERY VEHICLE', 'MOTORCYCLE',\n",
    "                 'PICK-UP TRUCK', 'LARGE COM VEH(6 OR MORE TIRES)', 'TAXI']\n",
    "y_cnt = Counter()\n",
    "i = 1 # plotting variable keeping track of column\n",
    "k = 1 # plotting variable keeping track of row\n",
    "j = 1 # plotting variable keeping track of axis number\n",
    "\n",
    "fig = tools.make_subplots(rows=5, cols=2, subplot_titles=(vehicle_types))\n",
    "\n",
    "# Run through each vehicle type\n",
    "for vehicle in vehicle_types:\n",
    "    # Make data structure with one collision category at a time\n",
    "    temp_values = traffic_data.loc[traffic_data['VEHICLE TYPE CODE 1'].isin([vehicle])]\n",
    "    # Add column with year\n",
    "    for year in [2013, 2014, 2015, 2016]:\n",
    "            y_cnt[year] = len(temp_values.loc[temp_values['YEAR'].isin([year])])\n",
    "    \n",
    "    trace = go.Bar(\n",
    "    x=y_cnt.keys(),\n",
    "    y=y_cnt.values()\n",
    "    )\n",
    "    fig.append_trace(trace, k, i)\n",
    "    fig['layout']['yaxis'+str(j)].update(title='Number of incidents', range=[0, max(y_cnt.values())])\n",
    "    \n",
    "    if(i < 2):\n",
    "        i += 1\n",
    "    else:\n",
    "        i = 1\n",
    "        k += 1\n",
    "    j += 1\n",
    "    \n",
    "fig['layout'].update(height=1200, width=1000, showlegend=False, title=\"Accidents per vehicle type 2013-2016\", margin=dict(b=200))\n",
    "py.iplot(fig, filename='subplot_vehicles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As in our previous assignments we have plotted the number of accidents for each year for some of the most common vehicle types involved in accidents. There are several patterns in the vehicle specific development of accidents from $2013-2016$. It looks as if the larger vehicles have had a decrease in number of accidents in 2016 compared to earlier years, whereas the number of accidents for passenger vehicles and motor cycles have increased. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\"> Number of traffic deaths</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~frksteenhoff2/64.embed\" height=\"500px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons_killed = traffic_data['NUMBER OF PERSONS KILLED'].replace(np.NaN, 'OTHER')\n",
    "kill_count = {}\n",
    "for val in traffic_data['YEAR'].unique():\n",
    "    if val != np.int64(2017) and val != np.int64(2012):\n",
    "        temp = traffic_data.loc[traffic_data['YEAR'].isin([val])]\n",
    "        kill_count[val] = int(temp['NUMBER OF PERSONS KILLED'].sum(axis=0))\n",
    "\n",
    "#killed = ex.createBarPlot(kill_count, 'Number of persons killed per year, 2012-2017', 'Year', 'Number of deaths', 'deaths_all', bgBorder, ticksAxes, 150)\n",
    "#killed\n",
    "killed = ex.createXYBarPlot(kill_count.keys(), kill_count.values(), 'Number of persons killed per year in NYC, 2012-2017', 'Year', 'Number of deaths', 'deaths_all', bgBorder, ticksAxes, 150)\n",
    "killed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Involved parties</span>\n",
    "* [Subplot documentation for Plotly](https://plot.ly/python/subplots/)\n",
    "\n",
    "#### A slowly decreasing trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]  [ (1,3) x3,y3 ]  [ (1,4) x4,y4 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~frksteenhoff2/48.embed\" height=\"600px\" width=\"1100px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting needed information\n",
    "focus_group = ['NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST KILLED']\n",
    "focus = {}\n",
    "\n",
    "# Creating initial figure for subplots\n",
    "fig = tools.make_subplots(rows=1, cols=4, subplot_titles=(\"2013\", \"2014\", \"2015\", \"2016\"))\n",
    "\n",
    "i = 1 # Keeping track of plot grid columns\n",
    "k = 1 # Setting axis range for all y axes \n",
    "    \n",
    "for year in years_of_interest:\n",
    "    for group in focus_group:\n",
    "        yearly_data = traffic_data.loc[traffic_data['YEAR'].isin([year])]\n",
    "        focus[group] = yearly_data[group].sum()\n",
    "    \n",
    "    trace = go.Bar(\n",
    "    x=focus.keys(),\n",
    "    y=focus.values(),\n",
    "    name=year\n",
    "    )\n",
    "    # Add plot to figure\n",
    "    fig.append_trace(trace, 1, i)\n",
    "    fig['layout']['yaxis'+str(k)].update(title='Year', range=[0, 180])\n",
    "    \n",
    "    i += 1 \n",
    "    k += 1\n",
    "\n",
    "# Plot result\n",
    "fig['layout'].update(height=600, width=1100, showlegend=False, title='Casualties per year in NYC traffic accidents', margin=dict(b=200))\n",
    "py.image.save_as(fig, filename='subplots-deaths.png')\n",
    "py.iplot(fig, filename='simple-subplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of people killed in traffic accidents in New York is slowly decreasing.\n",
    "\n",
    "### <span style=\"color:darkred\">Borough with most deaths?</span>\n",
    "Data and geoplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~frksteenhoff2/68.embed\" height=\"700px\" width=\"900px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding all incidents were people got killed as a result of the collisions\n",
    "killed_inc = traffic_data.loc[traffic_data['NUMBER OF PERSONS KILLED'] != 0]\n",
    "killed_per_borough = killed_inc['BOROUGH'].replace(np.NaN, 'UNKNOWN')\n",
    "borough_cnt = ex.countSamples(killed_per_borough)\n",
    "\n",
    "# Plot count per borough\n",
    "borough = ex.createBarPlot(borough_cnt, \"Persons killed per borough 2012-2017\", 'Borough', 'Number of person killed', 'killed_per_borough_all', bgBorder, ticksAxes, 200)\n",
    "borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, of the traffic accidents identified, from 2012-2017, the most of them happens in Brooklyn. If we do not account for all the unknown locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Are the incidents prone to happen at a specific time of day?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]  [ (1,3) x3,y3 ]\n",
      "[ (2,1) x4,y4 ]  [ (2,2) x5,y5 ]  [ (2,3) x6,y6 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~frksteenhoff2/52.embed\" height=\"1200px\" width=\"1000px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bor = [\"Unknown\", 'BROOKLYN', 'BRONX', 'MANHATTAN', 'QUEENS', 'STATEN ISLAND']\n",
    "n = ex.plotBarInSubplotGrid(2, 3, bor, \"Incidents in NYC per hour\", traffic_data, 'BOROUGH', 'HOUR', 'hourly', 21000, 1000, 1200)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'most_common'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-00ba18ecdf8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Count incidents in each borough\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mborough_cnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcountSamples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'HOUR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mhour_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mborough\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mborough_cnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Save data structure to json object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'most_common'"
     ]
    }
   ],
   "source": [
    "# Saving number of accidents per borough per year to json object for website\n",
    "hour_dict = {}\n",
    "for borough in bor:\n",
    "    wrk = traffic_data.loc[traffic_data['BOROUGH'].isin([borough])]\n",
    "    # Count incidents in each borough\n",
    "    borough_cnt = countSamples(wrk['HOUR'])\n",
    "    hour_dict[borough] = dict(borough_cnt.most_common())\n",
    "\n",
    "# Save data structure to json object\n",
    "with open('hour_data.json', 'w') as fp:\n",
    "    json.dump(hour_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like New York acutally sleeps -- for an hour! Of course, this is an overall picture and we cannot draw many conclusions based on this. Yes, most accidents happens between 8AM and 8PM, but, it would be better to look at the individual boroughs, wouldn't it?\n",
    "\n",
    "Lets check that out!\n",
    "From looking at this we cannot say more about the trend. We can see that most accidents happens in Queens and Brooklyn, but besides this, the times in which the majority of the accidents happen are the same, except from the fact that Manhatten, unlike the others do not have the \"morning peak\" from $8-9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Accidents according to time of year -- does it have any impact?</span>\n",
    "<span style=\"color:red\">Should we include this?</span>\n",
    "We have actively chosen to remove all incidents without any geolocation in order to plot the results more correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~frksteenhoff2/82.embed\" height=\"500px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding all incidents were people got killed as a result of the collisions\n",
    "bor2016 = traffic_data.loc[traffic_data['YEAR'].isin([2016])]\n",
    "borough_cnt = ex.countSamples(bor2016['BOROUGH'])\n",
    "\n",
    "# Plot count per borough\n",
    "bor = ex.createXYBarPlot(borough_cnt.keys(), borough_cnt.values(), \"Accidents per borough in 2016\", 'Borough', 'Number of person killed', 'accidents_per_borough_2016', bgBorder, ticksAxes, 200)\n",
    "bor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">What can we use this for?</span>\n",
    "Looking at the geodata, we can see that the areas most commonly exposed to traffic accidents are Midtown (around Times Square),  East Village and Lower Manhattan along with Brooklyn Heights and around Flushing Meadows Corona Park. Which in fact changes the picture of where there are most accidents. From looking solely at the number of accidents in each borough, we had a lot of missing data, but it seems as though a lot of the missing data belongs to Manhattan, which can also be seen from the heatmap that clearly shows Manhattan as the area most exposed to traffic accidents!\n",
    "\n",
    "Is this because it would be better (imagewise) for NYC that one of the lesser visited boroughs had the highest number of crimes?\n",
    "\n",
    "#### <span style=\"color:darkred\">So the funny thing is..</span>\n",
    "Looking at the plots, somehow, we get the feeling that in August and September there are less traffic accidents, but **this is wrong** actually, there are just as many but for both months more than $84\\%$ of the traffic accidents **are not properly reported** -- at least all the geodata info is missing! Is this because a lot of accidents attract less tourists in the summer? \n",
    "\n",
    "Take a look below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "----\n",
    "## <span style=\"color:darkred\">The Demographics of New York</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "      <th>population</th>\n",
       "      <th>sqMi</th>\n",
       "      <th>sqKm</th>\n",
       "      <th>personsPerSqMi</th>\n",
       "      <th>personsPrSqKm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>1644518</td>\n",
       "      <td>22.83</td>\n",
       "      <td>59.1</td>\n",
       "      <td>72033.00</td>\n",
       "      <td>27826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>1455444</td>\n",
       "      <td>42.00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>34653.00</td>\n",
       "      <td>13231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>2636735</td>\n",
       "      <td>71.00</td>\n",
       "      <td>180.0</td>\n",
       "      <td>37137.00</td>\n",
       "      <td>14649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Queens</td>\n",
       "      <td>2339150</td>\n",
       "      <td>109.00</td>\n",
       "      <td>280.0</td>\n",
       "      <td>21.46</td>\n",
       "      <td>8354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Staten Island</td>\n",
       "      <td>474558</td>\n",
       "      <td>58.50</td>\n",
       "      <td>152.0</td>\n",
       "      <td>8112.00</td>\n",
       "      <td>3132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         borough  population    sqMi   sqKm  personsPerSqMi  personsPrSqKm\n",
       "0      Manhattan     1644518   22.83   59.1        72033.00          27826\n",
       "1          Bronx     1455444   42.00  110.0        34653.00          13231\n",
       "2       Brooklyn     2636735   71.00  180.0        37137.00          14649\n",
       "3         Queens     2339150  109.00  280.0           21.46           8354\n",
       "4  Staten Island      474558   58.50  152.0         8112.00           3132"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demographics of New York \n",
    "ny_demographics = pd.read_excel('NY_demographics.xlsx')\n",
    "ny_demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: [Demographics of new York - Wikipedia](https://en.wikipedia.org/wiki/Demographics_of_New_York_City)\n",
    "\n",
    "* Number of fatalities/population\n",
    "* Basic plotting/statistics\n",
    "\n",
    "<span style=\"color:red\">Can we do some more with this? - I was thinking using it as underlying choropleth layer on shapefile?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRONX 0.0131850183458\n",
      "BROOKLYN 0.0148978593474\n",
      "MANHATTAN 0.00822342783784\n",
      "QUEENS 0.00926960648099\n",
      "STATEN ISLAND 0.0456909376725\n"
     ]
    }
   ],
   "source": [
    "# Find number of people per square kilometer for each borough in NYC\n",
    "i = 0\n",
    "for values in ['BRONX', 'BROOKLYN', 'MANHATTAN', 'QUEENS', 'STATEN ISLAND']:\n",
    "    print values, float(borough_cnt['BRONX'])/ny_demographics.iloc[i,1]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~frksteenhoff2/72.embed\" height=\"500px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot person per square kilometer\n",
    "ppl_pr_sqkm = ex.createXYBarPlot(ny_demographics['borough'], ny_demographics['personsPrSqKm'], \"Number of people per square kilometer\", 'Borough', 'Number of people', 'ppl_pr_sqkm', bgBorder, ticksAxes, 100)\n",
    "ppl_pr_sqkm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot it is made clear that indeed Manhattan has a great deal of people per square kilometer. **Manhattan has in fact more than double the amount of people compared any of the neighbouring boroughs**. Naturally one should expect more incidents here, since more people makes for a more activity both on the sidewalks and in the streets. One thing one also have to take into account is the high number of people visitng Manhattan which without a doubt will make the number of people per square kilometer even higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## <span style=\"color:darkred\">Theory - theoretical tools</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Machine learning tools and why tools chosen are right for our problem.</span>\n",
    "* **K-means**: We chose to cluster our data using K-means, as we wanted to know how the distribution of traffic accidents in NYC changed over the years. Since K-means is an unsupervised machine learning method it is a good choice to use when exploring data. Thus we decided not use any target data for the model. We chose data from may in 2013-2016 as the whole dataset contained too many observations for the clustering to run smoothly on the website.\n",
    "* **Decision tree**: We chose to use decision trees to predict the causes behind the accidents. We wanted to use more than just geolocation to predict on our data and a decision tree seemed fitting as it can use both categorical aswell as continous features at the same time. Furthermore it is also tool which can be easily visualized and understood by the reader. Decision trees can be used to find hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Model selection and splitting of data</span>\n",
    "* **K-means**: For clustering we didn't need to split the data into test and training sets, since we opted to model the data without targets. This decision also means that we didn't need (and couldn't use) cross validation to test our model preformance.\n",
    "* **Decision tree**: To later be able to test the preformance of the decision tree classifier we decided to split the data into a training and testing set. This split consited accordingly of 90 % and 10 % of the data with the use of the function train_test_split from the scikitlearn library. For the decision tree we decided to reduce the number of targets from the original 49 to the 10 most common factors. In regards to the features wetried using street name as a variable, but this decision resulted in gross overfitting. But why? The answer is simple. The feature of street names contain too many different categories as there of course are a lot of different streets in NYC. The model would make too many very specific rulesto fit the training data perfectly. Thus we decided to drop the feature from the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:darkred\">Model performance</span>\n",
    "* **K-means**: The lack of target data again means that model performance can't be done.\n",
    "* **Decision tree**: From splitting the dataset into training and test data we are able to measure preformance on the model on both the data subsets. This way we were able to see if our model overfitted to the training data. The preformance measure we used was just to see how big a percent of the datasets we predicted correctly. The final model we produced had a training and testing error of around 35.5 % which is not great but still better than random, which would be around 10 % since we have 10 different targets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkred\">Solutions for the machine learning methods</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">K-means clustering</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>ON STREET NAME</th>\n",
       "      <th>CROSS STREET NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>UNIQUE KEY</th>\n",
       "      <th>VEHICLE TYPE CODE 1</th>\n",
       "      <th>VEHICLE TYPE CODE 2</th>\n",
       "      <th>VEHICLE TYPE CODE 3</th>\n",
       "      <th>VEHICLE TYPE CODE 4</th>\n",
       "      <th>VEHICLE TYPE CODE 5</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>WEEKDAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>03/31/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.645615</td>\n",
       "      <td>-73.909900</td>\n",
       "      <td>(40.645615, -73.9099)</td>\n",
       "      <td>FOSTER AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3643404</td>\n",
       "      <td>PASSENGER VEHICLE</td>\n",
       "      <td>PASSENGER VEHICLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>03/31/2017</td>\n",
       "      <td>0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.762737</td>\n",
       "      <td>-73.839510</td>\n",
       "      <td>(40.762737, -73.83951)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3643942</td>\n",
       "      <td>SPORT UTILITY / STATION WAGON</td>\n",
       "      <td>PASSENGER VEHICLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007128</th>\n",
       "      <td>1007128</td>\n",
       "      <td>07/01/2012</td>\n",
       "      <td>9:57</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10065</td>\n",
       "      <td>40.765242</td>\n",
       "      <td>-73.957868</td>\n",
       "      <td>(40.7652424, -73.9578679)</td>\n",
       "      <td>1 AVENUE</td>\n",
       "      <td>EAST 68 STREET</td>\n",
       "      <td>...</td>\n",
       "      <td>44907</td>\n",
       "      <td>PASSENGER VEHICLE</td>\n",
       "      <td>TAXI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007129</th>\n",
       "      <td>1007129</td>\n",
       "      <td>07/01/2012</td>\n",
       "      <td>9:59</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10452</td>\n",
       "      <td>40.835397</td>\n",
       "      <td>-73.920305</td>\n",
       "      <td>(40.835397, -73.920305)</td>\n",
       "      <td>EAST 167 STREET</td>\n",
       "      <td>GERARD AVENUE</td>\n",
       "      <td>...</td>\n",
       "      <td>85154</td>\n",
       "      <td>PASSENGER VEHICLE</td>\n",
       "      <td>SPORT UTILITY / STATION WAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1007130 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        DATE  TIME    BOROUGH ZIP CODE   LATITUDE  \\\n",
       "0                 0  03/31/2017  0:00        NaN      NaN  40.645615   \n",
       "1                 1  03/31/2017  0:00        NaN      NaN  40.762737   \n",
       "...             ...         ...   ...        ...      ...        ...   \n",
       "1007128     1007128  07/01/2012  9:57  MANHATTAN    10065  40.765242   \n",
       "1007129     1007129  07/01/2012  9:59      BRONX    10452  40.835397   \n",
       "\n",
       "         LONGITUDE                   LOCATION  \\\n",
       "0       -73.909900      (40.645615, -73.9099)   \n",
       "1       -73.839510     (40.762737, -73.83951)   \n",
       "...            ...                        ...   \n",
       "1007128 -73.957868  (40.7652424, -73.9578679)   \n",
       "1007129 -73.920305    (40.835397, -73.920305)   \n",
       "\n",
       "                           ON STREET NAME                 CROSS STREET NAME  \\\n",
       "0        FOSTER AVENUE                                                  NaN   \n",
       "1                                     NaN                               NaN   \n",
       "...                                   ...                               ...   \n",
       "1007128  1 AVENUE                          EAST 68 STREET                     \n",
       "1007129  EAST 167 STREET                   GERARD AVENUE                      \n",
       "\n",
       "          ...   UNIQUE KEY            VEHICLE TYPE CODE 1  \\\n",
       "0         ...      3643404              PASSENGER VEHICLE   \n",
       "1         ...      3643942  SPORT UTILITY / STATION WAGON   \n",
       "...       ...          ...                            ...   \n",
       "1007128   ...        44907              PASSENGER VEHICLE   \n",
       "1007129   ...        85154              PASSENGER VEHICLE   \n",
       "\n",
       "                   VEHICLE TYPE CODE 2  VEHICLE TYPE CODE 3  \\\n",
       "0                    PASSENGER VEHICLE                  NaN   \n",
       "1                    PASSENGER VEHICLE                  NaN   \n",
       "...                                ...                  ...   \n",
       "1007128                           TAXI                  NaN   \n",
       "1007129  SPORT UTILITY / STATION WAGON                  NaN   \n",
       "\n",
       "         VEHICLE TYPE CODE 4  VEHICLE TYPE CODE 5  YEAR  MONTH  HOUR WEEKDAY  \n",
       "0                        NaN                  NaN  2017      3     0       4  \n",
       "1                        NaN                  NaN  2017      3     0       4  \n",
       "...                      ...                  ...   ...    ...   ...     ...  \n",
       "1007128                  NaN                  NaN  2012      7     9       6  \n",
       "1007129                  NaN                  NaN  2012      7     9       6  \n",
       "\n",
       "[1007130 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data set (used for both machine learning methods)\n",
    "filename = 'Traffic_data.csv'\n",
    "traffic_data = pd.read_csv(filename, low_memory=False)\n",
    "traffic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extracting coordinate data\n",
    "coordinates  = traffic_data[['LATITUDE','LONGITUDE','YEAR']].dropna(axis = 0, how = 'any')\n",
    "focus_years  = [2013,2014,2015,2016]\n",
    "\n",
    "# Number of clusters to use\n",
    "n_clusters   = 4\n",
    "\n",
    "# Initializing dictionaries to store data\n",
    "cluster_data = {}\n",
    "centroids    = {}\n",
    "\n",
    "for year in focus_years:\n",
    "    data = coordinates.loc[coordinates['YEAR'].isin([year])]\n",
    "    \n",
    "    # Train KMeans on data\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(data[['LATITUDE','LONGITUDE']])\n",
    "    \n",
    "    # Save the centroids to an array\n",
    "    centroid = kmeans.cluster_centers_\n",
    "    centroid_array = []\n",
    "    \n",
    "    for j in range(0,n_clusters):\n",
    "        centroid_cord = {}\n",
    "        centroid_cord['LATITUDE'] = centroid[j][0]\n",
    "        centroid_cord['LONGITUDE'] = centroid[j][1]\n",
    "        centroid_array.append(centroid_cord)\n",
    "    centroids[str(year)] = centroid_array\n",
    "    \n",
    "    data['CLUSTER'] = kmeans.predict(data[['LATITUDE','LONGITUDE']])\n",
    "    \n",
    "    cluster_data[str(year)] = data[['LATITUDE','LONGITUDE','CLUSTER']].to_dict('list')\n",
    "\n",
    "model_data = {}\n",
    "model_data['centroids'] = centroids\n",
    "model_data['datapoints'] = cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write JSON file with datapoints\n",
    "with io.open('model_data.json', 'w', encoding='utf8') as outfile:\n",
    "    str_ = json.dumps(model_data,\n",
    "                      indent=4, sort_keys=True,\n",
    "                      separators=(',', ':'), ensure_ascii=False)\n",
    "    outfile.write(to_unicode(str_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Decision Tree</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334947\n",
      "264187\n"
     ]
    }
   ],
   "source": [
    "# Duplicating data \n",
    "features  = ['CONTRIBUTING FACTOR VEHICLE 1','BOROUGH','NUMBER OF PERSONS KILLED','VEHICLE TYPE CODE 1',\n",
    "            'HOUR','WEEKDAY']\n",
    "tree_data = traffic_data[features]\n",
    "\n",
    "# Replacing NA's with 'OTHER' for vehicle type\n",
    "tree_data['VEHICLE TYPE CODE 1'].fillna('OTHER', inplace=True)\n",
    "\n",
    "tree_data = tree_data[tree_data['CONTRIBUTING FACTOR VEHICLE 1'] != 'Unspecified']\n",
    "tree_data = tree_data[tree_data['BOROUGH'] != 'UNKNOWN']\n",
    "tree_data = tree_data.dropna(axis = 0, how = 'any')\n",
    "\n",
    "# Remove uncommon contributing factors (as shown in plot of factors)\n",
    "common_factors = ['Driver Inattention/Distraction','Fatigued/Drowsy','Failure to Yield Right-of-Way',\n",
    "                  'Other Vehicular','Backing Unsafely','Turning Improperly','Lost Consciousness','Prescription Medication',\n",
    "                  'Traffic Control Disregarded','Driver Inexperience']\n",
    "\n",
    "print len(tree_data)\n",
    "tree_data = tree_data.loc[tree_data['CONTRIBUTING FACTOR VEHICLE 1'].isin(common_factors)]\n",
    "print len(tree_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tree_data[features[1:]]\n",
    "# Encode input values as an enumerated type or categorical variable\n",
    "X.loc[:,'BOROUGH']                  = pd.factorize(X['BOROUGH'])[0]\n",
    "#X.loc[:,'ON STREET NAME']          = pd.factorize(X['ON STREET NAME'])[0]\n",
    "X.loc[:,'NUMBER OF PERSONS KILLED'] = pd.factorize(X['NUMBER OF PERSONS KILLED'])[0]\n",
    "X.loc[:,'VEHICLE TYPE CODE 1']      = pd.factorize(X['VEHICLE TYPE CODE 1'])[0]\n",
    "X.loc[:,'HOUR']                     = pd.factorize(X['HOUR'])[0]\n",
    "X.loc[:,'WEEKDAY']                  = pd.factorize(X['WEEKDAY'])[0]\n",
    "\n",
    "y = pd.factorize(tree_data[features[0]])[0]\n",
    "\n",
    "# Splitting testing and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test score is:     0.341307392407\n",
      "The training score is: 0.371113858888\n"
     ]
    }
   ],
   "source": [
    "# Model training and prediction\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "test_pred = clf.predict(X_test)\n",
    "train_pred = clf.predict(X_train)\n",
    "\n",
    "print 'The test score is:    ', ex.score(test_pred,y_test)\n",
    "print 'The training score is:', ex.score(train_pred,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## <span style=\"color:darkred\">Visualizations</span>\n",
    "\n",
    "<span style=\"color:red\"> Should we chose something different on the webpage?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Explain the visualizations you've chosen.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:darkred\">Why are they right for the story you want to tell?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## <span style=\"color:darkred\">Discussion - critical thinking</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:darkred\">What went well?</span>\n",
    "* <span style=\"color:red\">Model selection and prediction, right?</span>\n",
    "* Set-up/design of webpage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:darkred\">What is still missing? What could be improved?, Why?</span>\n",
    "#### <span style=\"color:darkred\">Data-wise</span>\n",
    "Need to write more about\n",
    "\n",
    "* <span style=\"color:red\">Combining different datasets</span>\n",
    "* <span style=\"color:red\">Adding information about traffic density</span>\n",
    "* <span style=\"color:red\">Size of cluster file (but do include a lot of data</span>\n",
    "\n",
    "We really wanted to do some more work on the missing values in the dataset. We found the module ``geopy`` which lets you write an address and get corresponding geo location or the other way around, write geo location and get street information such as Street name, number, state, country etc. an example of both is given below.\n",
    "\n",
    "The problem however is that the API that is called to get the geo locations/address values only allow a minimum of calls per day and with a total of $32.396$ values for just location, this has been impossible to acheive. However we still wanted to mention it as this was our intention and probably would have been easy to do had we had a developer account. \n",
    "\n",
    "#### <span style=\"color:darkred\">Machine Learning</span>\n",
    "\n",
    "\n",
    "#### <span style=\"color:darkred\"> Visualizations</span>\n",
    "\n",
    "#### <span style=\"color:darkred\"> Overall in the solution</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkred\">References</span>\n",
    "In relation to traffic in New York City, we have found a few sources describing the traffic in New York and some previous visualizations:\n",
    "#### <span style=\"color:darkred\">Related articles and inspiration</span>\n",
    "\n",
    "<span style=\"color:red\">Need to write these more academically correct!</span>\n",
    "\n",
    "* Decreasing number of [Traffic deaths in NYC](https://www.nytimes.com/2016/01/02/nyregion/number-of-traffic-deaths-in-new-york-falls-for-a-second-year-in-a-row.html?_r=0)\n",
    "* [**Viewing.nyc's**](https://viewing.nyc/) really got it!\n",
    "  * [Visualization of NYC traffic data](https://viewing.nyc/see-wazes-hypnotic-visualization-of-new-york-city-traffic-patterns/)\n",
    "  * [Distracted driving in New York](https://viewing.nyc/heres-a-scary-map-of-all-distracted-driving-collisions-in-new-york-city/)\n",
    "* [ArcGIS Population/Traffic](https://www.arcgis.com/home/webmap/viewer.html?webmap=df41300d3d4344baa080c86349bfd59b)\n",
    "* [YouTube-inspiration](https://www.youtube.com/watch?v=QFv7AFRmmTs)\n",
    "* [Blocks.org - Bar charts](http://bl.ocks.org/juan-cb/faf62e91e3c70a99a306)\n",
    "\n",
    "* [Vision Zero - basic information](nyc.gov/visionzero)\n",
    "* [Vision Zero - accident map](nyc.gov/visionzero)\n",
    "This map has been created in relation to Vision Zero and has a lot of information about speed limits, where accidents happen (year-by-year), risk areas, number of accidents per precinct etc.\n",
    "* [Scrolling as opposed to clicking!](https://bost.ocks.org/mike/scroll/)\n",
    "* [Shapefile](http://www1.nyc.gov/site/planning/data-maps/open-data/districts-download-metadata.page)\n",
    "* [Choropleth map](https://bl.ocks.org/mbostock/4060606)\n",
    "* [Switching between images](http://stackoverflow.com/questions/13975891/change-image-in-html-page-every-few-seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
